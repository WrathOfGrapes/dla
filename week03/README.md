# Week 03

# Slides
__TBA__

* Automatic speech recognition (ASR)
* Metrics for ASR
* CTC loss function
* "Listen, Attend and Spell" archetecture
* Beam-search

### Prerequisites

* This lecture assumes you are familiar with the __attention mechanism__. If you're not feeling confident about this
  topic, we recommend that you read one of the following materials:
    * [How Attention works in Deep Learning: understanding the attention mechanism in sequence models](https://theaisummer.com/attention/)
        * Simple language. Easy to understand. Quite detailed. Not too technical. Surface knowledge.
    * [Sequence to Sequence (seq2seq) and Attention](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)
        * Nicely illustrated. Detailed math explanations. A bit bulk.

### Practice & homework

__TBA__
* Audio augmentations with code and examples
* Practical excersises
    * Writing and testing WER-metric
    * Implementing CTC decoding
    * Implementing CTC beam-search
* (*bonus!*) Intro to PyCharm

### Additional Materials

__TBA__

